tokenizer:
  library: 'megatron'
  type: 'GPT2BPETokenizer'
  model: null
  vocab_file: null
  merge_file: null 
  delimiter: null # only used for tabular tokenizer
service:
  filepath: null
  max_answer_length: 128
  cross_encoder: null # fine tuned cross encoder
  port: 17111  # server port number